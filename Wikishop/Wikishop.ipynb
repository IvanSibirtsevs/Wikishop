{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "\n",
    "Нужно обучить модель классифицировать комментарии на позитивные и негативные. В моем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**План по выполнению проекта**\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели. \n",
    "3. Сделать выводы.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "import re \n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import notebook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Подключаем библиотеки***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/datasets/toxic_comments.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"\\n\\nIn your theoretical situation, a single r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bear, I hope you are not angry with me, I was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\" A second opinion will brought in to see if t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Needs sources\\nThis article has a lot of text ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If you will check the image out, you will see ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>message on daedalus' page \\n\\nDaedalus is noth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>]\\nIT'S HER EXACT QUOTE.  WHAT CAN'T YOU UNDER...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>important \\n\\nYou Suck! I think you should go ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>last warning to you \\n\\nHEY LOSER\\n\\nDO WHATEV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>fk u bitch \\n\\ni h8 u enit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  toxic\n",
       "0    \"\\n\\nIn your theoretical situation, a single r...      0\n",
       "1    Bear, I hope you are not angry with me, I was ...      0\n",
       "2    \" A second opinion will brought in to see if t...      0\n",
       "3    Needs sources\\nThis article has a lot of text ...      0\n",
       "4    If you will check the image out, you will see ...      0\n",
       "..                                                 ...    ...\n",
       "195  message on daedalus' page \\n\\nDaedalus is noth...      1\n",
       "196  ]\\nIT'S HER EXACT QUOTE.  WHAT CAN'T YOU UNDER...      1\n",
       "197  important \\n\\nYou Suck! I think you should go ...      1\n",
       "198  last warning to you \\n\\nHEY LOSER\\n\\nDO WHATEV...      1\n",
       "199                         fk u bitch \\n\\ni h8 u enit      1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t = data.loc[data['toxic'] == 1]\n",
    "data_t = data_t.sample(100).reset_index(drop=True)\n",
    "\n",
    "data_g = data.loc[data['toxic'] == 0]\n",
    "data_g = data_g.sample(100).reset_index(drop=True)\n",
    "df_tweets = pd.concat([data_g,data_t], ignore_index=True)\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Проверка на пропуски***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    m = Mystem()\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    "        \n",
    "    return lemm_text\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    text = (re.sub(r'[^a-zA-Z ]', ' ', text)).split() \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf42b3f99e94e0ba19be336ba15307f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = df_tweets['text'].values.astype('U')\n",
    "a = []\n",
    "for i in notebook.tqdm(range(len(df_tweets))):    \n",
    "    a.append(lemmatize(clear_text(corpus[i])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"\\n\\nIn your theoretical situation, a single r...</td>\n",
       "      <td>0</td>\n",
       "      <td>In your theoretical situation a single revert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bear, I hope you are not angry with me, I was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bear I hope you are not angry with me I was tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\" A second opinion will brought in to see if t...</td>\n",
       "      <td>0</td>\n",
       "      <td>A second opinion will brought in to see if thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Needs sources\\nThis article has a lot of text ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Needs sources This article has a lot of text t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If you will check the image out, you will see ...</td>\n",
       "      <td>0</td>\n",
       "      <td>If you will check the image out you will see t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>message on daedalus' page \\n\\nDaedalus is noth...</td>\n",
       "      <td>1</td>\n",
       "      <td>message on daedalus page Daedalus is nothing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>]\\nIT'S HER EXACT QUOTE.  WHAT CAN'T YOU UNDER...</td>\n",
       "      <td>1</td>\n",
       "      <td>IT S HER EXACT QUOTE WHAT CAN T YOU UNDERSTAND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>important \\n\\nYou Suck! I think you should go ...</td>\n",
       "      <td>1</td>\n",
       "      <td>important You Suck I think you should go suck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>last warning to you \\n\\nHEY LOSER\\n\\nDO WHATEV...</td>\n",
       "      <td>1</td>\n",
       "      <td>last warning to you HEY LOSER DO WHATEVER YOU ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>fk u bitch \\n\\ni h8 u enit</td>\n",
       "      <td>1</td>\n",
       "      <td>fk u bitch i h u enit\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  toxic  \\\n",
       "0    \"\\n\\nIn your theoretical situation, a single r...      0   \n",
       "1    Bear, I hope you are not angry with me, I was ...      0   \n",
       "2    \" A second opinion will brought in to see if t...      0   \n",
       "3    Needs sources\\nThis article has a lot of text ...      0   \n",
       "4    If you will check the image out, you will see ...      0   \n",
       "..                                                 ...    ...   \n",
       "195  message on daedalus' page \\n\\nDaedalus is noth...      1   \n",
       "196  ]\\nIT'S HER EXACT QUOTE.  WHAT CAN'T YOU UNDER...      1   \n",
       "197  important \\n\\nYou Suck! I think you should go ...      1   \n",
       "198  last warning to you \\n\\nHEY LOSER\\n\\nDO WHATEV...      1   \n",
       "199                         fk u bitch \\n\\ni h8 u enit      1   \n",
       "\n",
       "                                             lemm_text  \n",
       "0    In your theoretical situation a single revert ...  \n",
       "1    Bear I hope you are not angry with me I was tr...  \n",
       "2    A second opinion will brought in to see if thi...  \n",
       "3    Needs sources This article has a lot of text t...  \n",
       "4    If you will check the image out you will see t...  \n",
       "..                                                 ...  \n",
       "195  message on daedalus page Daedalus is nothing b...  \n",
       "196  IT S HER EXACT QUOTE WHAT CAN T YOU UNDERSTAND...  \n",
       "197  important You Suck I think you should go suck ...  \n",
       "198  last warning to you HEY LOSER DO WHATEVER YOU ...  \n",
       "199                            fk u bitch i h u enit\\n  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['lemm_text'] = a\n",
    "corpus = df_tweets['lemm_text'].values.astype('U')\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (200, 2371)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Выгружаем базу***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_tweets, test_size=0.25, shuffle=True, random_state=42)\n",
    "\n",
    "x_train = train.drop(columns=['toxic', 'text'])\n",
    "y_train = train['toxic']\n",
    "\n",
    "x_test = test.drop(columns=['toxic', 'text'])\n",
    "y_test = test['toxic']\n",
    " \n",
    "text_transformer = ColumnTransformer(remainder='passthrough', transformers=[('vectorizer', TfidfVectorizer(stop_words=stopwords), 'lemm_text')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114    1\n",
       "173    1\n",
       "5      0\n",
       "126    1\n",
       "117    1\n",
       "      ..\n",
       "106    1\n",
       "14     0\n",
       "92     0\n",
       "179    1\n",
       "102    1\n",
       "Name: toxic, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Делим выборки на тренировочную и тестовую и лмматизацию***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 ms, sys: 0 ns, total: 27.1 ms\n",
      "Wall time: 28.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('text_transformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('vectorizer',\n",
       "                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                  binary=False,\n",
       "                                                                  decode_error='strict',\n",
       "                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                  encoding='utf-8',\n",
       "                                                                  input='content',\n",
       "                                                                  lowercase=True,\n",
       "                                                                  max_df=1.0,\n",
       "                                                                  max_features=None,\n",
       "                                                                  m...\n",
       "                                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                                  tokenizer=None,\n",
       "                                                                  use_idf=True,\n",
       "                                                                  vocabulary=None),\n",
       "                                                  'lemm_text')],\n",
       "                                   verbose=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=5, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=12345,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model1 = Pipeline(steps=[\n",
    "    ('text_transformer', text_transformer),\n",
    "    ('model', LogisticRegression(C = 5, random_state=12345))\n",
    "])\n",
    " \n",
    "model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.9 ms, sys: 506 µs, total: 41.4 ms\n",
      "Wall time: 42.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('text_transformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('vectorizer',\n",
       "                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                  binary=False,\n",
       "                                                                  decode_error='strict',\n",
       "                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                  encoding='utf-8',\n",
       "                                                                  input='content',\n",
       "                                                                  lowercase=True,\n",
       "                                                                  max_df=1.0,\n",
       "                                                                  max_features=None,\n",
       "                                                                  m...\n",
       "                                                                  vocabulary=None),\n",
       "                                                  'lemm_text')],\n",
       "                                   verbose=False)),\n",
       "                ('model',\n",
       "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features=None,\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=12345,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model2 = Pipeline(steps=[\n",
    "    ('text_transformer', text_transformer),\n",
    "    ('model', DecisionTreeClassifier(random_state=12345))\n",
    "])\n",
    " \n",
    "model2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 ms, sys: 5.73 ms, total: 52.5 ms\n",
      "Wall time: 75.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('text_transformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('vectorizer',\n",
       "                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                  binary=False,\n",
       "                                                                  decode_error='strict',\n",
       "                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                  encoding='utf-8',\n",
       "                                                                  input='content',\n",
       "                                                                  lowercase=True,\n",
       "                                                                  max_df=1.0,\n",
       "                                                                  max_features=None,\n",
       "                                                                  m...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=12345,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model3 = Pipeline(steps=[\n",
    "    ('text_transformer', text_transformer),\n",
    "    ('model', RandomForestClassifier(random_state=12345))\n",
    "])\n",
    " \n",
    "model3.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Обучаем модели***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7307692307692308\n"
     ]
    }
   ],
   "source": [
    "predicted_valid = model1.predict(x_train)\n",
    "print(f1_score(predicted_valid, y_train)) # F1\n",
    "\n",
    "predicted_valid = model1.predict(x_test)\n",
    "print(f1_score(predicted_valid, y_test)) # F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7586206896551724\n",
      "CPU times: user 27 ms, sys: 6.06 ms, total: 33 ms\n",
      "Wall time: 31.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_valid = model2.predict(x_train)\n",
    "print(f1_score(predicted_valid, y_train)) # F1\n",
    "\n",
    "predicted_valid = model2.predict(x_test)\n",
    "print(f1_score(predicted_valid, y_test)) # F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7272727272727273\n",
      "CPU times: user 17.5 ms, sys: 9.04 ms, total: 26.5 ms\n",
      "Wall time: 44.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_valid = model3.predict(x_train)\n",
    "print(f1_score(predicted_valid, y_train)) # F1\n",
    "\n",
    "predicted_valid = model3.predict(x_test)\n",
    "print(f1_score(predicted_valid, y_test)) # F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Тестируем модели***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Params/Model  | LogisticRegression   | DecisionTreeClassifier | RandomForestClassifier |\n",
    "| :------------- | :-------------: |:-------------: |:-------------: |\n",
    "| Время Обучения  | 49.8 ms  | 66 ms  | 71.4 ms | \n",
    "| Время выполнения     | 34.7 ms   |39.3 ms | 65.7 ms| \n",
    "| |  | | | | |\n",
    "| Качество на обучающей выборке (F1)  | 1.0    |1.0  | 0.99 | \n",
    "| Качество на тестовой выборке (F1)    | 0.78 |0.61  |0.69| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать вывод, что заказчику больше всего подойдет модель LogisticRegression. Она самая быстрая и качественная."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
